#------------------------------------------------------------------------------
# Custom slurm config for UB-HPC cluster
#------------------------------------------------------------------------------
ClusterName=ubhpc

AuthType=auth/none

SlurmUser=nikolays
SlurmdUser=root
ControlMachine=localhost
ControlAddr=localhost

ReturnToService=1
#CryptoType=crypto/munge
MessageTimeout=60
JobRequeue=0

StateSaveLocation=/home/slurm/work/medium_cluster/var/state
#PrologFlags=Alloc,Contain,X11
AcctGatherEnergyType=acct_gather_energy/none
AcctGatherNodeFreq=30
MaxStepCount=1000
PreemptType=preempt/partition_prio
PreemptMode=REQUEUE


#SlurmctldPort=6817
#SlurmctldParameters=enable_configless
#SlurmdPort=6818


SlurmdParameters=config_overrides


ProctrackType=proctrack/pgid
#ProctrackType=proctrack/linuxproc
SwitchType=switch/none
TopologyPlugin=topology/tree
TaskPlugin=task/none

FirstJobId=1

UsePAM=0
GresTypes=gpu



#
# TIMERS
#
SlurmctldTimeout=300
SlurmdTimeout=300
InactiveLimit=0
MinJobAge=300
KillWait=30
Waittime=0

#
# SCHEDULING
# 
SchedulerType=sched/backfill
SchedulerParameters=bf_max_job_user=100,bf_window=4320,bf_interval=120,bf_max_job_test=2500,default_queue_depth=2500,bf_continue,max_script_size=1048576
FairShareDampeningFactor=5
SlurmSchedLogFile=/home/slurm/work/medium_cluster/log/sched.log
SelectType=select/cons_tres
SelectTypeParameters=CR_Core_Memory,CR_CORE_DEFAULT_DIST_BLOCK
PriorityType=priority/multifactor
PriorityDecayHalfLife=30-0
# The larger the job, the greater its job size priority.
PriorityFavorSmall=NO
#PriorityWeightFairshare=50000
# 1/20/21 - changed to 80,000.
# 4/06/21 - changed to 100,000.
# 8/30/21 - changed to 120,000.
PriorityWeightFairshare=120000
PriorityWeightAge=70000
PriorityWeightPartition=1000000
PriorityWeightJobSize=200000
PriorityWeightQOS=50000
# The job's age factor reaches 1.0 after waiting in the
# queue for 2 weeks.
PriorityMaxAge=7-0

# jobs which exceed a partition's size and/or time limits will be rejected at
# submission time
EnforcePartLimits=YES

#
# TRES (defaults below )
# 
#AccountingStorageTRES=gres/gpu
#PriorityWeightTRES=CPU=1000,Mem=2000,GRES/gpu=3000

# 3/31/20 - Increased to 30,000 per gpu to ensure these jobs
# jump to the front of the cascade partition. 
PriorityWeightTRES=CPU=0,Mem=.03,GRES/gpu=30000
PriorityFlags=NO_NORMAL_TRES

#
# LOGGING
#
SlurmctldDebug=info
SlurmdDebug=info
#DebugFlags=Agent,Backfill,BackfillMap,SelectType
DebugFlags=Backfill
SlurmSchedLogLevel=1

SlurmctldLogFile=/home/slurm/work/medium_cluster/log/slurmctld.log
SlurmdLogFile=/home/slurm/work/medium_cluster/log/slurmd.log
SlurmdSpoolDir=/home/slurm/work/medium_cluster/var/spool
StateSaveLocation=/home/slurm/work/medium_cluster/var/state

JobCompType=jobcomp/filetxt
JobCompLoc=/home/slurm/work/medium_cluster/log/jobcomp.log

#
# Mail for job effeciency, depends on the seff package being installed
#
#MailProg=/usr/bin/smail

#
# ACCOUNTING
#
JobAcctGatherType=jobacct_gather/linux

JobAcctGatherFrequency=30
JobAcctGatherParams=UsePss,NoOverMemoryKill

AccountingStorageType=accounting_storage/slurmdbd
AccountingStorageEnforce=associations,limits,qos
AccountingStorageTRES=gres/gpu
AccountingStoreFlags=job_comment
#,job_script,job_env

AccountingStorageHost=localhost

#RebootProgram=/sbin/reboot
ResumeTimeout=1000

PropagateResourceLimits=CORE

VSizeFactor=0
KillOnBadExit=1

#
# Node health checks
#
#HealthCheckProgram=/usr/sbin/nhc.ccr
#HealthCheckInterval=300

#------------------------------------------------------------------------------
# COMPUTE NODES (totally 217 nodes)
#------------------------------------------------------------------------------
# 187G RAM
NodeName=DEFAULT RealMemory=187000 Sockets=2 CoresPerSocket=16 Weight=60
NodeName=n[001-087] Feature=CPU-Gold-6130,OPA
NodeName=gn[001-002] Gres=gpu:tesla_p100-pcie-16gb:2 Feature=CPU-Gold-6130,OPA,P100 Weight=190

# 187G RAM
NodeName=DEFAULT CPUs=40 RealMemory=187000 Sockets=2 CoresPerSocket=20 ThreadsPerCore=1
NodeName=g[001-008] Gres=gpu:tesla_v100-pcie-32gb:2 Feature=CPU-Gold-6230,IB,V100 Weight=190
NodeName=m[001-096] Feature=CPU-Gold-6230,IB Weight=70

# 754G RAM
NodeName=DEFAULT RealMemory=754000 Sockets=2 CoresPerSocket=20
NodeName=b[001-024] Feature=CPU-Gold-6230,IB Weight=160

PartitionName=DEFAULT State=UP DefaultTime=24:00:00 MaxTime=72:00:00
PartitionName=general-compute Nodes=n[001-087],m[001-096],b[001-024],g[001-008] Default=YES DefMemPerCPU=2800 Priority=100 AllowQOS=general-compute,supporters,priority,priority-supporters QOS=general-compute
PartitionName=debug Nodes=gn[001-002] MaxTime=01:00:00 DefMemPerCPU=2800 Priority=700 AllowQOS=debug,supporters QOS=debug

FrontendName=localhost
